<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Performance Metrics · GMMParameterEstimation.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">GMMParameterEstimation.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Performance Metrics</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Performance Metrics</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/HaleyColgateKottler/GMPE.jl/blob/master/docs/src/performanceMetrics.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Performance-Metrics"><a class="docs-heading-anchor" href="#Performance-Metrics">Performance Metrics</a><a id="Performance-Metrics-1"></a><a class="docs-heading-anchor-permalink" href="#Performance-Metrics" title="Permalink"></a></h1><p>The following scripts were used to check errors and runtime.</p><h2 id="Error-Calculations"><a class="docs-heading-anchor" href="#Error-Calculations">Error Calculations</a><a id="Error-Calculations-1"></a><a class="docs-heading-anchor-permalink" href="#Error-Calculations" title="Permalink"></a></h2><p>Since parameter sets are identified up to permutation, the following finds the permutation that best reduces the error of the mixing coefficients and applies it to the means and covariances to compute their respective errors.</p><pre><code class="language-julia hljs">function computeError(w, true_means, true_covariances, mixing_coefficients, means, covariances, diagonal)
    k = size(w)[1]
    d = size(true_means)[2]

    basis = 1:k

    minimum_weight_error = (norm(w - mixing_coefficients), basis)
    for i in 2:factorial(k)
        permutation = nthperm(basis, i)
        mixed_weights = Array{Float64}(undef, size(w))
        for j in 1:k
            mixed_weights[j, 1:end] = mixing_coefficients[permutation[j], 1:end]
        end
        weight_error = norm(mixed_weights - w)
        (weight_error &lt; minimum_weight_error[1]) &amp;&amp; (minimum_weight_error = (weight_error, permutation))
    end

    permutation = minimum_weight_error[2]

    final_mixing_coefficients = Array{Float64}(undef, size(mixing_coefficients))
    final_means = Array{Float64}(undef, size(means))

    if diagonal
        final_covariances = []
        for j in 1:k
            final_mixing_coefficients[j] = mixing_coefficients[permutation[j]]
            final_means[j, 1:end] = means[permutation[j], 1:end]
            push!(final_covariances, covariances[permutation[j]][1:end, 1:end])
        end
    else
    final_covariances = Array{Union{Float64}, 3}(undef, (k,d,d))
        for j in 1:k
            final_mixing_coefficients[j] = mixing_coefficients[permutation[j]]
            final_means[j, 1:end] = means[permutation[j], 1:end]
            final_covariances[j, 1:end, 1:end] = covariances[permutation[j], 1:end, 1:end]
        end
    end

    mixing_error = norm(final_mixing_coefficients - w)
    means_error = norm(final_means - true_means)
    covariance_error = norm(final_covariances - true_covariances)

    return (mixing_error, means_error, covariance_error)
end</code></pre><p>This is similar, but for Algorithm 2 from <a href="https://arxiv.org/abs/2106.15675">Estimating Gaussian Mixtures Using Sparse Polynomial Moment Systems</a> all but the means are known so it merely permutes the means to find the minimum error permutation and then returns that error.</p><pre><code class="language-julia hljs">function computeErrorAlg2(true_mean, est_mean)
    k = size(true_mean)[1]
    d = size(true_mean)[2]

    basis = 1:k

    minimum_error = norm(true_mean - est_mean)
    for i in 2:factorial(k)
        permutation = nthperm(basis, i)
        mixed_means = Array{Float64}(undef, size(true_mean))
        for j in 1:k
            mixed_means[j, 1:end] = est_mean[permutation[j], 1:end]
        end
        mean_error = norm(mixed_means - true_mean)
        (mean_error &lt; minimum_error) &amp;&amp; (minimum_error = mean_error)
    end

    return minimum_error
end</code></pre><h2 id="Tests"><a class="docs-heading-anchor" href="#Tests">Tests</a><a id="Tests-1"></a><a class="docs-heading-anchor-permalink" href="#Tests" title="Permalink"></a></h2><p>The following tests performance while adding specified levels of noise to the denoised moments. This relies on the above listed <code>computeError</code> function.</p><pre><code class="language-julia hljs">function testNoise(d, k, diagonal, noise_levels, reps, known_mixing_coeffs)
    passes = []
    mix_errs = []
    mean_errs = []
    covar_errs = []
    timings = []

    for noise in noise_levels
        passing = 0
        mixing_error = 0
        means_error = 0
        covariance_error = 0
        times = 0

        for i in 1:reps
            w, true_means, true_covariances = generateGaussians(d, k, diagonal)
            if diagonal
                true_first, true_diag = diagonalPerfectMoments(d, k, w, true_means, true_covariances)
                num_moments = 3*k + (d-1)*(2*k+1)
            else
                true_first, true_diag, true_others = densePerfectMoments(d, k, w, true_means, true_covariances)
                num_moments = 3*k + (d-1)*(2*k+1) + k*(d^2-d)/2
            end

            if noise&gt;0
                randomness = randn(Int64(num_moments))
                randomness = noise/norm(randomness) * randomness

                noisy_first = true_first + [0, randomness[1:3*k]...]
                noisy_diag = true_diag + reshape(randomness[3*k+1:3*k + (d-1)*(2*k+1)], (d-1,2*k+1))

                if !diagonal
                    noisy_others = Dict{Vector{Int64}, Float64}()
                    orig = []
                    new = []
                    counter = 3*k + (d-1)*(2*k+1) + 1
                    for (key, moment) in true_others
                        push!(orig, moment)
                        push!(new, moment + randomness[counter])
                        noisy_others[key] = moment + randomness[counter]
                        counter += 1
                    end
                end
            else
                noisy_first = true_first
                noisy_diag = true_diag
                if !diagonal
                    noisy_others = true_others
                end
            end

            pass = false
            if diagonal
                if known_mixing_coeffs
                    timing = @elapsed begin
                        pass, (mixing_coefficients, means, covariances) = estimate_parameters(d, k, w, noisy_first, noisy_diag)
                    end
                else
                    timing = @elapsed begin
                        pass, (mixing_coefficients, means, covariances) = estimate_parameters(d, k, noisy_first, noisy_diag)
                    end
                end
            else
                if known_mixing_coeffs
                    timing = @elapsed begin
                        pass, (mixing_coefficients, means, covariances) = estimate_parameters(d, k, w, noisy_first, noisy_diag, noisy_others)
                    end
                else
                    timing = @elapsed begin
                        pass, (mixing_coefficients, means, covariances) = estimate_parameters(d, k, noisy_first, noisy_diag, noisy_others)
                    end
                end
            end

            if pass == true
                passing += 1
                (mix, mean, cov) = computeError(w, true_means, true_covariances, mixing_coefficients, means, covariances, diagonal)
                mixing_error += mix
                means_error += mean
                covariance_error += cov
                times += timing
            end
        end
        push!(passes, passing)
        if passing &gt; 0
            push!(mix_errs, mixing_error/passing)
            push!(mean_errs, means_error/passing)
            push!(covar_errs, covariance_error/passing)
            push!(timings, times/passing)
        else
            push!(mix_errs, nothing)
            push!(mean_errs, nothing)
            push!(covar_errs, nothing)
            push!(timings, nothing)
        end
        open(&quot;noise_test_d&quot; * string(d) * &quot;_k&quot; * string(k) * &quot;_diag&quot; * string(diagonal) * &quot;_knoww&quot; * string(known_mixing_coeffs) * &quot;.txt&quot;, &quot;w&quot;) do file
            write(file, &quot;reps: &quot; * string(reps) * &quot;\nnoise levels: &quot; * string(noise_levels) * &quot;\npasses: &quot; * string(passes) * &quot;\naverage mixing coefficient error: &quot; * string(mix_errs) * &quot;\naverage mean error: &quot; * string(mean_errs) * &quot;\naverage covariance error: &quot; * string(covar_errs) * &quot;\naverage time: &quot; * string(timings) * &quot;\n&quot;)
        end
        println(&quot;check&quot;)
    end
end</code></pre><p>Example of use:</p><pre><code class="language-julia hljs">k = 3
d = 5
diag = true
known = false
testNoise(d, k, diag, [.1, .01, .001, .0001, 0], 10, known)</code></pre><p>The following tests performance with 100 samples per parameter, cycling over dimensions to find candidate mixing coefficients if the solver is unsuccessful with prior mixing coefficient candidates.  This relies on the above listed <code>computeError</code> function.</p><pre><code class="language-julia hljs">function testSampleAlg2(d, k, reps)
    num_params = k*d
    num_samples = 200*num_params

    passing = 0
    means_error = 0
    times = 0

    w = (1/k)*ones(k)

    for i in 1:reps
        shared_cov = makeCovarianceMatrix(d, false)
        true_mean = randn(k,d)

        variances = Array{Float64, 3}(undef, (k,d,d))
        for i in 1:k
            variances[i, 1:end, 1:end] = copy(shared_cov)
        end

        sample = getSample(num_samples, w, true_mean, variances)
        variances = []

        m1, m2 = equalMixCovarianceKnown_moments(k, sample)

        timing = @elapsed begin
            pass, est_mean = estimate_parameters(k, shared_cov, m1, m2)
        end
        if pass == true
            passing += 1
            means_error += computeErrorAlg2(true_mean, est_mean)
            times += timing
        end
    end

    if passing &gt; 0
        means_error = means_error/passing
        times = times/passing
    else
        means_error = nothing
        times = nothing
    end

    open(&quot;alg2_sample_test_d&quot; * string(d) * &quot;_k&quot; * string(k) * &quot;.txt&quot;, &quot;w&quot;) do file
        write(file, &quot;reps: &quot; * string(reps) * &quot;\npasses: &quot; * string(passing) * &quot;\naverage mean error: &quot; * string(means_error) * &quot;\naverage time: &quot; * string(times) * &quot;\n&quot;)
    end
end</code></pre><p>Example of use:</p><pre><code class="language-julia hljs">k = 2
diagonal = true
d = 10
reps = 100
testSampleCycle(d, k, diagonal, reps)</code></pre><p>The following tests performance of Algorithm 2 from <a href="https://arxiv.org/abs/2106.15675">Estimating Gaussian Mixtures Using Sparse Polynomial Moment Systems</a> for denoised moments. This relies on the above listed <code>computeErrorAlg2</code> function.</p><pre><code class="language-julia hljs">function testPerfectAlg2(d, k, reps)
    passing = 0
    means_error = 0
    times = 0

    for i in 1:reps
        shared_cov = makeCovarianceMatrix(d, false)
        true_mean = randn(k,d)
        m1, m2 = equalMixCovarianceKnown_moments(k, true_mean, shared_cov)

        timing = @elapsed begin
            pass, est_mean = estimate_parameters(k, shared_cov, m1, m2)
        end
        if pass == true
            passing += 1
            means_error += computeErrorAlg2(true_mean, est_mean)
            times += timing
        end
    end

    if passing &gt; 0
        means_error = means_error/passing
        times = times/passing
    else
        means_error = nothing
        times = nothing
    end

    open(&quot;alg2_perfect_test_d&quot; * string(d) * &quot;_k&quot; * string(k) * &quot;.txt&quot;, &quot;w&quot;) do file
        write(file, &quot;reps: &quot; * string(reps) * &quot;\npasses: &quot; * string(passing) * &quot;\naverage mean error: &quot; * string(means_error) * &quot;\naverage time: &quot; * string(times) * &quot;\n&quot;)
    end
end</code></pre><p>The following tests performance of Algorithm 2 from <a href="https://arxiv.org/abs/2106.15675">Estimating Gaussian Mixtures Using Sparse Polynomial Moment Systems</a> for sample moments with 200 samples per parameter. This relies on the above listed <code>computeErrorAlg2</code> function.</p><pre><code class="language-julia hljs">function testSampleAlg2(d, k, reps)
    num_params = k*d
    num_samples = 200*num_params

    passing = 0
    means_error = 0
    times = 0

    w = (1/k)*ones(k)

    for i in 1:reps
        shared_cov = makeCovarianceMatrix(d, false)
        true_mean = randn(k,d)

        variances = Array{Float64, 3}(undef, (k,d,d))
        for i in 1:k
            variances[i, 1:end, 1:end] = copy(shared_cov)
        end

        sample = getSample(num_samples, w, true_mean, variances)
        variances = []

        m1, m2 = equalMixCovarianceKnown_moments(k, sample)

        timing = @elapsed begin
            pass, est_mean = estimate_parameters(k, shared_cov, m1, m2)
        end
        if pass == true
            passing += 1
            means_error += computeErrorAlg2(true_mean, est_mean)
            times += timing
        end
    end

    if passing &gt; 0
        means_error = means_error/passing
        times = times/passing
    else
        means_error = nothing
        times = nothing
    end

    open(&quot;alg2_sample_test_d&quot; * string(d) * &quot;_k&quot; * string(k) * &quot;.txt&quot;, &quot;w&quot;) do file
        write(file, &quot;reps: &quot; * string(reps) * &quot;\npasses: &quot; * string(passing) * &quot;\naverage mean error: &quot; * string(means_error) * &quot;\naverage time: &quot; * string(times) * &quot;\n&quot;)
    end
end</code></pre></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.23 on <span class="colophon-date" title="Tuesday 1 August 2023 15:39">Tuesday 1 August 2023</span>. Using Julia version 1.7.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
